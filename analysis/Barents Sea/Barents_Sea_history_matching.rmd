---
title: "Emulating trait-based models 3: Barents Sea"
author: "Philipp Neubauer"
date: "09/11/2015"
output: md_document
---

# Emulating trait-based models 3: Barents Sea


```{r preamble,echo=F,message=F,results='hide'}
#require("mizer")
require("parallel")
require("ggplot2")
require(dplyr)
require(knitr)
opts_chunk$set(cache=TRUE, autodep=TRUE,message=F,warning = F)
source("../includes/GP_emulators/helper_funcs.R")
files <- paste0('../includes/size_spectra/', dir('../includes/size_spectra'))
sapply(files, source)


config <- yaml::yaml.load_file('History_matching_config.yaml')

```

## Building an emulator



```{r make training data}
load(file='History_matching_start.Rdata')

sims=config$waves[[1]]$sims

minmax <- data.frame(
                     kappa = c(param$kappaPP/10,param$kappaPP*10)
                     )
    
LHC <- latin.hypercube(sims,1)

LHC_in <- data.frame(sapply(1:ncol(LHC), function(x)
  LHC[,x]*diff(minmax[,x])+minmax[1,x]))

LHC_in <- cbind(t(repmat(param$h,1,sims)),t(repmat(param$Rmax,1,sims)),LHC_in)

colnames(LHC_in) <- c(sprintf('h%d',1:config$nspec),sprintf('Rmax%d',1:config$nspec),'kappa')
#plot(LHC_in)

pred_list <- split(LHC_in,1:nrow(LHC_in))       
system.time( simdat <- parallel::mclapply(pred_list,
                                          run_nis_spec,
                                          state=state,
                                          mc.cores = 4))

simdats <-  lapply(simdat,function(pred){
  if(is.numeric(pred[1])) pred
  else rep(NA,config$nspec)})

sim_data <- t(do.call('cbind',simdats))


```


```{r check first outputs, Wave 0 of checking for predictions that are wayy off}
#naset <- which(apply(sim_data,1,function(x) any(is.na(x) | x<1000)))
#sim_data <- sim_data[-naset,]
biom <- state$SSBio

# observation error - should be set to actual uncertainty, but harder for aggregate term
Vobs <- diag(biom*0.2)
Vdiscr <- 0.2*diag(diag(cov(sim_data)))

svar <- solve(Vobs + Vdiscr)

LHC_in$impl  <- do.call('c', lapply(simdats,function(pred){
  t(biom - pred) %*% 
    svar %*% 
    (biom - pred)
})) 

 with(LHC_in,plot(kappa,impl))
 abline(h=qchisq(0.95,13))
 
LHC_in$preg <- LHC_in$impl < qchisq(0.9999,13)

kappas <- LHC_in$kappa[LHC_in$preg]

```

```{r}

sims=config$waves[[2]]$sims

hminmax <- rbind(param$h/2,param$h*2)
Rminmax <- log(rbind(param$Rmax/100,param$Rmax*100))

minmax <- data.frame(hminmax,
                     Rminmax,
                     kappa = c(min(kappas),max(kappas))
                     )
    
LHC <- latin.hypercube(sims,13)

LHC_in2 <- data.frame(sapply(1:ncol(LHC), function(x)
  LHC[,x]*diff(minmax[,x])+minmax[1,x]))

colnames(LHC_in2) <- c(sprintf('h%d',1:config$nspec),sprintf('Rmax%d',1:config$nspec),'kappa')
LHC_in2[,grepl('Rmax',colnames(LHC_in2))] <- exp(LHC_in2[,grepl('Rmax',colnames(LHC_in2))])
#plot(LHC_in2)

pred_list <- split(LHC_in2,1:nrow(LHC_in2))       
system.time( simdat <- parallel::mclapply(pred_list,
                                          run_nis_spec,
                                          state=state,
                                          mc.cores = 4))

simdats <-  lapply(simdat,function(pred){
  if(is.numeric(pred[1])) pred
  else rep(NA,config$nspec)})

sim_data <- t(do.call('cbind',simdats))

plot(LHC_in2$Rmax3,LHC_in2$h3,cex=sim_data[,3]/biom[3])
points(param$Rmax[3],param$h[3],cex=biom[3]/biom[3],bg='red',col='red',pch=16)

```
First, source Johnathan Rougiers code: 
```{r source OPE code}

source("../includes/GP_emulators/OPE.R")

```

I can now define a GP emulator:

```{r define OPE}
  # stdise is a normal centering and fixing to [-1,1], whereas stdise_wrt(x,y) is with respect to the mean and max of y 


ins <- stdise(as.matrix(LHC_in2))

outs <- stdise(log(sim_data))
bioms<- stdise_wrt(t(as.matrix(log(biom))),log(sim_data))

scales <- (0.125*as.vector(diff(apply(ins,2,range))))^2
out_grid <- seq(from=log10(min(state$wInf)), to = log10(max(state$wInf)), length=config$nspec)
out_grid <- (out_grid-mean(out_grid))/sd(out_grid)

OPE <- define_OPE(1000,
                  rep(0.2,13),
                  inData = ins,
                  outGrid = out_grid,
                  outData = outs)
 
preds <- config$waves[[2]]$preds
LHC_pred <- latin.hypercube(preds,13)

LHC_pred <- data.frame(sapply(1:ncol(LHC_pred), function(x)
  LHC_pred[,x]*diff(minmax[,x])+minmax[1,x]))

colnames(LHC_pred) <- colnames(LHC_in2)
LHC_pred[,grepl('Rmax',colnames(LHC_pred))] <- exp(LHC_pred[,grepl('Rmax',colnames(LHC_pred))])

pred_in <- stdise_wrt(LHC_pred, LHC_in2)
div=100
pred_in_list <- split(data.frame(pred_in), rep(seq(1,round(nrow(pred_in)/div)),each=div))

pred <- mclapply(pred_in_list, 
                      function(ins) emulate(ins,
                                            OPE,
                                            split=F,
                                            rev_std_out=F,
                                            rev_std_data=log(sim_data)),
                      mc.cores = 4)

pred[1]

prd <- reshape_preds(pred)


  Vobs <- diag(bioms*0.05)
  
impl <- get_impl(prd, bioms, Vobs = Vobs, Vdiscr = diag(0.01,6))

```

```

I now use the remaining points that were not discarded (there aren't many!) to define a set of point to build the emulator on. This avoids training the emulator on a set of parameters and outputs that give widely different answers and dominate the model fit, but lead to poor predictions in the area of interest (i.e., parameters that make sense). The new set is made by drawing from a multivariate normal distribution around the remaining points to explore the space around those points.

```{r update training set}

leftovers <- LHC_in[!LHC_in$p_reg,1:13]
oc = round(500/nrow(leftovers))
isd <- cov(leftovers)

# draw from mv norm around leftover values
new_pred_pre_list_jitter <- t(apply(repmat(leftovers,oc,1),1,function(x) t(mvtnorm::rmvnorm(1,x,0.05*isd))))

#remove values <0
new_pred_pre_list_jitter <- new_pred_pre_list_jitter[(apply(new_pred_pre_list_jitter,1,function(x) !any(x<=0))),]

colnames(new_pred_pre_list_jitter) <- colnames(LHC_in)[1:13]

mp <- reshape2::melt(new_pred_pre_list_jitter)
ggplot(mp,aes(x=value)) + 
  geom_histogram(aes(x=value)) + 
  facet_wrap(~Var2,scales='free') + 
  theme_bw()+ 
  xlab('Parameter')
```

Running the simulator to make a training set for the emulator:

```{r run training set}
                        
new_pred_list <- split(data.frame(new_pred_pre_list_jitter),
                       1:nrow(new_pred_pre_list_jitter))   

system.time( new_simdat <- parallel::mclapply(new_pred_list,
                                              run_nis_spec,
                                              mc.cores = 4))

```

I throw out some combinations of parameters that lead to collapse. In a full history matching exerciser I wouldn't want to do this since they hold information about areas of poor fit to the data - but here I use it to show that the emulator can indeed give OK (and fast!) predictions of the size spectrum in the parameter space of interest.

```{r subset simdata}
new_sim_data <- t(do.call('cbind',new_simdat))

apply(new_sim_data,2,quantile)

pred_pre_list_df <- data.frame(new_pred_pre_list_jitter)
pred_pre_list_df$p_reg <- apply(new_sim_data,1,function(x) any(x<(min(biom)/10^4)))

mpreds <- reshape2::melt(pred_pre_list_df)

ggplot(mpreds) + 
  facet_grid( p_reg ~ variable,scales = "free") + 
  geom_bar(aes(x=value)) + 
  theme_bw() + 
  xlab('Parameter')


keepers <-  !is.na(pred_pre_list_df$p_reg) & !(pred_pre_list_df$p_reg)

sim_data <- new_sim_data[keepers,]

sim_data <- unique(sim_data)

pred_pre_list <- unique(new_pred_pre_list_jitter[keepers,])

```

Time to think about how to emulate this model. In general, species are linked in the model, so uni-variate emulation seems like the wrong approach. An alternative is multivariate emulation. In particular, the method described in @rougier:2008:efficient may be appropriate here since we are working with a standard matrix of outputs. The method assumes that the predictions can be decomposed into a regression in the inputs and a regression in the outputs (i.e., the size classes).

First, source Johnathan Rougiers code: 
```{r source OPE code}

source("../includes/GP_emulators/OPE.R")

```

For the method to work, we need to specify regressors on the inputs and outputs, along with a covariance, computed from the inputs and at points where the simulator is evaluated (i.e., where we calculate the biomass - at w\_inf for each species). I use the same for inputs and outputs here as I have little prior idea. For the mean part of the GP regression, a second order polynomial seems like a relatively flexible start. Tor the covariance, I will start with an exponential covariance for simplicity. Later, I will try to learn the scale parameters of both matrices in order to optimise the emulator. The functions for means, variances and other helper functions are defined [here](2015-11-09-MV-emulating-size-based-models_files/helper_funcs.R)

I can now define a GP emulator:

```{r define OPE}
  # stdise is a normal centering and fixing to [-1,1], whereas stdise_wrt(x,y) is with respect to the mean and max of y 


ins <- stdise(as.matrix(pred_pre_list))

outs <- stdise(log(sim_data))

scales <- 1/(0.125*as.vector(diff(apply(ins,2,range))))^2
out_grid <- seq(from=log10(min(state$wInf)), to = log10(max(state$wInf)), length=6)
out_grid <- (out_grid-mean(out_grid))/sd(out_grid)

OPE <- define_OPE(c(1,1*(scales)),
                  inData = ins,
                  outGrid = out_grid,
                  outData = outs)
 

test_pred <- mclapply(ins_test_sp, 
                      function(ins) emulate(ins,
                                            OPE,
                                            split=F,
                                            rev_std_out=T,
                                            rev_std_data = log(sim_data_train)),
                      mc.cores = 4)

test_pred <- do.call('rbind',test_pred)

```

### How well does the emulator perform?

For these inputs, it seems as though the emulator does well in interpolating the results from the size-spectrum for most of the test set:

```{r testing}

plot(exp(test_pred$mu),as.vector(t((sim_data_test))),xlab='Predictions',ylab='Simulations')
abline(a=0,b=1)
summary(lm(exp(test_pred$mu)~0+as.vector(t((sim_data_test)))))

```

### Improving the emulator

It might be possible to get even better prediction by adjusting the length scale of the GP covariances. For this, I use a function to optimise the length scales based on the GP marginal likelihoods, and then define the new emulator by those length scales:

```{r optimise OPE,results='hide',message=F}

opt_OPE <- optim(c(1,(scales)),
      define_OPE,
      inData = stdise(as.matrix(pred_pre_list)),
      outGrid = out_grid,
      outData = stdise(log(sim_data)),
      opt=T,
      control = list(fnscale=-1,
                     trace = 100,
                     reltol = 1e-6))

```
The new emulator with optimised GP length scales is now:

```{r test refined OPE}
OPE_opt <- define_OPE(opt_OPE$par,
                      inData = stdise(as.matrix(pred_pre_list)),
                      outGrid = out_grid,
                      outData = stdise(log(sim_data)))

OPE_opt_test <- adjustOPE(OPE_opt, R = ins, Y = outs)


test_pred <- mclapply(ins_test_sp, 
                      function(ins) emulate(ins,
                                            OPE_opt_test,
                                            split=F,
                                            rev_std_out=T,
                                            rev_std_data = log(sim_data_train)),
                      mc.cores = 4)

test_pred <- do.call('rbind',test_pred)

plot(exp(test_pred$mu),as.vector(t(sim_data_test)),xlab='Predictions',ylab='Simulations')
abline(a=0,b=1)
summary(lm(exp(test_pred$mu)~0+as.vector(t(sim_data_test))))

```

Indeed, now 75% of predictions are within ```quantile(abs((exp(test_pred$mu)-as.vector(t(sim_data_test)))/as.vector(t(sim_data_test)))*100)[4]```% of the simulations.

## Can the emulator emulate the size-spectrum response?

To test the emulator, its worthwhile testing how well the emulator predicts the marginal responses to changes in the inputs:

```{r test opt_OPT response}
in_df <- data.frame(pred_pre_list)

pred_size <- 8

testset1 <- data.frame(h=seq(min(in_df$h),max(in_df$h),l=pred_size),
                       r_pp = 10,
                       sigma= 1.3)

test_em(testset1, 
        OPE_opt, 
        'h')

testset2 <- data.frame(h=40,
                       r_pp = 10,
                       sigma= seq(min(in_df$sigma),max(in_df$sigma),l=pred_size))

test_em(testset2, 
        OPE_opt, 
        'sigma')

testset3 <- data.frame(h=40,
                       r_pp = lseq(quantile(in_df$r_pp,0.05),quantile(in_df$r_pp,0.95),l=pred_size),
                       sigma= 1.3)

test_em(testset3, 
        OPE_opt, 
        'r_pp')

```

This looks pretty promising! Especially given a big caveats here: the parameter sets over which these marginal responses were estimated may not all be plausible. However, I also removed some implausible inputs further up to improve model fits in relevant regions - so I cheated a bit. But all in all this looks like a promising way forward, and I will follow this up with a more elaborate example of emulation and history matching next.


## References
<br>
